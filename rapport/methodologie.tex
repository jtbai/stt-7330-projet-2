\section{Méthodologie}

\subsection{Présentation du jeu de données}
Le jeu de données utilisé dans ce travail est composés de différentes statistiques sur les match officiels de l'association des professionnels de tennis depuis 1968. Il est distribuées par Jeff Sackmann via github. 

Le jeu de données comprend la surface sur laquelle un match de tennis a été joué. C'est cette variable que la machine apprenante devra prédire.  Il s'agit d'une variable catégorielle pouvant prendre 3 valeurs  soit: Clay, Hard et Carpet. Il y a environ 50 autres variables qui sont utilisées pour tenter d'expliquer la variable à prédire. Ces valeurs représentent soit des caractéristiques sur le tournois (Niveau, endoit), sur les joueurs (age, pays d'orgine, main forte) ou sur la partie (score final, nombre de ACE pour le gagnant, longueur de la partie en minute).


\subsection{Prétraîtement des données}
L'information contenue dans le jeu de données étaient très clairsemée, de telle sorte que l'apprentissage se faisait de façon sous optimale. Les modèles finaux peuvent ne pas être optimaux ou fiable. Afin de palier à ce problème nous avons décidé d'améliorer la qualité du jeu de données. Les différentes étapes ont été de nettoyager des données, l'identification et le traitement des valeurs manquantes, intégration et transformation des variables, et enfin la réduction de la dimensionnalité.

- Nettoyage des données

- Traitement des valeurs manquantes

- \italic{Feature engineering} 
Cette étape est une étape cruciale qui permettent de créer d'autres variables qui va permettre d'avoir un meilleur modèle. Le choix de ces variables est essentiellement basé sur notre intuition et notre compréhension de la base de donnée et du domaine.
En fait, on a crée  11 variables qui sont sous forme de proportion:

- Réduction de la dimensionalité
Vu que la fouille de donnnées peut être très longue sur les données "l'analyse des composantes principales (PCA)", celle-ci permet d'obtenir une représentation réduite du jeu de données, plus petit volume mais qui produit les mêmes (ou presque) résultats analytiques. L'ACP a réduit le nombre des variables et \italic{features} utilisées à 7 variables tout en maintenant une quatité de variance expliquée de 80 \%. 

\subsection{Classifieurs utilisés}

Les algorithmes d'apprentissage automatique utilisés pour le projets varient en complexité. Nous désirions tester différents niveaux de complexité afin de déterminer si une augmentation de la complexité était justifiée relativement à la qualité des prédictions. Nous avons librement sous divisés les algorithme en 3 catégories distinctes. 

La première catégorie d'algoritme les plus simple ne demande qu'une compréhension du modèle afin de l'utiliser. Les modèles comme 
- le classifieur de naïf de Bayes, 
- le classifieur régression logistique, 
- l'analyse discriminante linéaire et 
- l'analyse discriminante quadratique 

font partie de cette première catégorie. Nous considérons qu'ils sont simple car ils sont utilisables directement avec une fonction R. 

La deuxième catégorie d'algoritmes sont un peu plus complexes et demandent un ajustement de leur hyper-paramètres. Les modèles comme 
- le classifieur par arbre, 
- le classifieur forêt aléatoire et 
- le classifieur SVM 

font parti de cette deuxième catégories. La méthodologie de la sélection des hyper-paramètres est présentée dans une section ultérieure.

Finalement, la troisième catégorie d'algoritme sont les plus complexe et demandent l'utilisation de l'expérience et l'intuition du statisticien. Les modèles comme 
- les réseaux de neuronnes et 
- le modèle par emsemble 

font parti de cette troisième catégorie. L'utilisation et l'architecture de ces modèles seront présentés dans une section ultérieure

\subsection{Ajustement des hyper-paramètres}

L'ajustement des hyper-paramètre a été faite par une recherche exhaustive. La technique de recherche par quadrillage (grid-search) 


\subsection{}

