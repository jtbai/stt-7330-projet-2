\documentclass{article}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage[utf8]{inputenc}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[french]{babel}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\begin{document}
\SweaveOpts{concordance=TRUE}

<<echo = FALSE>>=
# Load packages
library(data.table)
library(jsonlite)
library(knitr)
library(kableExtra)

# Import functions
source("performance_measures.R")

# Import data
prediction <- fread("data/prediction_rapport.csv")
models <- colnames(prediction[, -(c("split", "true_response")), with = FALSE])
model_name <- gsub(".preds", "", models)

performance_train <- data.table(model_name, do.call(rbind, lapply(models, function(model){
  get_performance(model.preds = model, prediction_matrix = prediction[split == "train"])$measures_performance
})))
performance_test <- data.table(model_name, do.call(rbind, lapply(models, function(model){
  get_performance(model.preds = model, prediction_matrix = prediction[split == "test"])$measures_performance
})))
performance_validation <- data.table(model_name, do.call(rbind, lapply(models, function(model){
  get_performance(model.preds = model, prediction_matrix = prediction[split == "validation"])$measures_performance
})))

colnames(performance_train) <- c("modeles", as.character(get_performance(models[1], prediction)$measures_names))
colnames(performance_test) <- c("modeles", as.character(get_performance(models[1], prediction)$measures_names))
colnames(performance_validation) <- c("modeles", as.character(get_performance(models[1], prediction)$measures_names))

# Import data
prediction_pca <- fread("data/prediction_rapport_pca.csv")
models_pca <- colnames(prediction_pca[, -(c("split", "true_response")), with = FALSE])
model_name_pca <- gsub(".preds", "", models_pca)

performance_train_pca <- data.table(model_name_pca, do.call(rbind, lapply(models_pca, function(model){
  get_performance(model.preds = model, prediction_matrix = prediction_pca[split == "train"])$measures_performance
})))
performance_test_pca <- data.table(model_name_pca, do.call(rbind, lapply(models_pca, function(model){
  get_performance(model.preds = model, prediction_matrix = prediction_pca[split == "test"])$measures_performance
})))
performance_validation_pca <- data.table(model_name_pca, do.call(rbind, lapply(models_pca, function(model){
  get_performance(model.preds = model, prediction_matrix = prediction_pca[split == "validation"])$measures_performance
})))

colnames(performance_train_pca) <- c("modeles", as.character(get_performance(models_pca[1], prediction_pca)$measures_names))
colnames(performance_test_pca) <- c("modeles", as.character(get_performance(models_pca[1], prediction_pca)$measures_names))
colnames(performance_validation_pca) <- c("modeles", as.character(get_performance(models_pca[1], prediction_pca)$measures_names))

setkey(performance_train, modeles)
setkey(performance_train_pca, modeles)
performance_train_tot <- merge(performance_train, performance_train_pca, all.x = TRUE)
performance_train_tot$modeles <- c("Bayes", "Ensemble", "LDA", "Multinomial", "Réseau de neurones", "QDA", "Forêt aléatoire", "SVM Gaussien", "Arbre de décision")
performance_train_tot <- performance_train_tot[order(-average_accuracy.x)]

setkey(performance_test, modeles)
setkey(performance_test_pca, modeles)
performance_test_tot <- merge(performance_test, performance_test_pca, all.x = TRUE)
performance_test_tot$modeles <- c("Bayes", "Ensemble", "LDA", "Multinomial", "Réseau de neurones", "QDA", "Forêt aléatoire", "SVM Gaussien", "Arbre de décision")
performance_test_tot <- performance_test_tot[order(-average_accuracy.x)]

@

<<performances, echo=FALSE, results=tex>>=
kable(performance_train_tot, format = "latex", digits = 2, row.names = FALSE, col.names = c("Modèles", "Exactitude", "F-Score", "Exactitude avec PCA", "F-Score avec PCA"), align = c("l", rep("c", length(ncol(performance_train) - 1))), booktabs = T, caption = "Performances des différents modèles sur le jeu de données d'entraînement selon les différentes mesures de performance.") %>% kable_styling(latex_options = c("striped", "scale_down"))

kable(performance_test_tot, format = "latex", digits = 2, row.names = FALSE, col.names = c("Modèles", "Exactitude", "F-Score", "Exactitude avec PCA", "F-Score avec PCA"), align = c("l", rep("c", length(ncol(performance_test) - 1))), booktabs = T, caption = "Performances des différents modèles sur le jeu de données d'entraînement selon les différentes mesures de performance.") %>% kable_styling(latex_options = c("striped", "scale_down"))

@

<<confusion_matrix, echo=FALSE, results=tex>>=
chosen_model <- "neural_net.preds"
confusion_matrix <- function(preds, true_response) {
  
  nb_classes <- length(unique(preds))
  confusion_matrix <- matrix(NA, nb_classes, nb_classes)
  for (i in 1:nb_classes) {
    for (j in 1:nb_classes) {
      confusion_matrix[i, j] <- sum((preds == i) & (true_response == j))
    }
  }
  confusion_matrix
}

confusion_matrix <- confusion_matrix(preds = prediction[[chosen_model]], true_response = prediction[["true_response"]])
colnames(confusion_matrix) <- c("Hard", "Clay", "Grass")
rownames(confusion_matrix) <- c("Hard", "Clay", "Grass")


kable(confusion_matrix, format = "latex", align = c("l", rep("c", length(model_name))), booktabs = T, caption = "Matrice de confusion pour le modèle final.") %>% kable_styling(latex_options = c("striped"))
@




\end{document}